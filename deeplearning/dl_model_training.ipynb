{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep learning model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "학습 데이터 : 2021, 2022   \n",
    "검증 데이터 : 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# df_2023 = pd.read_csv('data/learningdata2/testdata_2023.csv',encoding='utf-8')\n",
    "\n",
    "df_2022 = pd.read_csv('data/learningdata2/testdata_2022.csv',encoding='utf-8')\n",
    "df_2021 = pd.read_csv('data/learningdata2/testdata_2021.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일시</th>\n",
       "      <th>호선</th>\n",
       "      <th>역번호</th>\n",
       "      <th>역명</th>\n",
       "      <th>주말</th>\n",
       "      <th>요일</th>\n",
       "      <th>통과호선수</th>\n",
       "      <th>미세먼지(pm10)</th>\n",
       "      <th>시간</th>\n",
       "      <th>하차인원</th>\n",
       "      <th>공휴일여부</th>\n",
       "      <th>강수량(mm)</th>\n",
       "      <th>평균기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>최고기온</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>시청</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>종각</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>종로3가</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>종로5가</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>동대문</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>신설동</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>제기동</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>청량리(서울시립대입구)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>동묘앞</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           일시  호선  역번호            역명  주말  요일  통과호선수  미세먼지(pm10)  시간  하차인원  \\\n",
       "0  2022-01-01   1  150           서울역   1   5      4        29.0   6   560   \n",
       "1  2022-01-01   1  151            시청   1   5      2        29.0   6   195   \n",
       "2  2022-01-01   1  152            종각   1   5      1        28.0   6   136   \n",
       "3  2022-01-01   1  153          종로3가   1   5      3        28.0   6   139   \n",
       "4  2022-01-01   1  154          종로5가   1   5      1        28.0   6    80   \n",
       "5  2022-01-01   1  155           동대문   1   5      2        28.0   6    59   \n",
       "6  2022-01-01   1  156           신설동   1   5      3        29.0   6    84   \n",
       "7  2022-01-01   1  157           제기동   1   5      1        29.0   6    82   \n",
       "8  2022-01-01   1  158  청량리(서울시립대입구)   1   5      1        29.0   6   129   \n",
       "9  2022-01-01   1  159           동묘앞   1   5      2        28.0   6    77   \n",
       "\n",
       "   공휴일여부  강수량(mm)  평균기온  최저기온  최고기온  \n",
       "0      1      0.0  -4.3 -10.2   2.3  \n",
       "1      1      0.0  -4.3 -10.2   2.3  \n",
       "2      1      0.0  -4.3 -10.2   2.3  \n",
       "3      1      0.0  -4.3 -10.2   2.3  \n",
       "4      1      0.0  -4.3 -10.2   2.3  \n",
       "5      1      0.0  -4.3 -10.2   2.3  \n",
       "6      1      0.0  -4.3 -10.2   2.3  \n",
       "7      1      0.0  -4.3 -10.2   2.3  \n",
       "8      1      0.0  -4.3 -10.2   2.3  \n",
       "9      1      0.0  -4.3 -10.2   2.3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2022.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 데이터 설정 : 역번호, 요일(1~7), 통과 호선수, 미세먼지, 시간, 공휴일 여부, 강수량, 최저기온, 평균기온, 최고기온"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustDf(temp_df):\n",
    "\treturn_df = temp_df[['역번호','요일','통과호선수','미세먼지(pm10)','시간','하차인원','공휴일여부','강수량(mm)','최저기온','평균기온','최고기온']]\n",
    "\t# 결측치 제거\n",
    "\treturn_df = return_df.dropna()\n",
    "\t# 시간 23시 제거\n",
    "\treturn_df = return_df[return_df['시간'] != 23]\n",
    "\t# 하차인원 로그변환\n",
    "\treturn_df['하차인원'] = return_df['하차인원'].apply(np.log1p)\n",
    "\t# Scaler\n",
    "\tcolumns_to_scale = ['미세먼지(pm10)', '평균기온', '최저기온', '최고기온', '강수량(mm)']\n",
    "\twith open('../models/scaler.pkl', 'rb') as f:\n",
    "\t\tloaded_scaler = pickle.load(f)\n",
    "\treturn_df[columns_to_scale] = loaded_scaler.transform(return_df[columns_to_scale])\n",
    "\treturn return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_df_2021 = adjustDf(df_2021)\n",
    "adjust_df_2022 = adjustDf(df_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424735 entries, 0 to 3424734\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   역번호         int64  \n",
      " 1   요일          int64  \n",
      " 2   통과호선수       int64  \n",
      " 3   미세먼지(pm10)  float64\n",
      " 4   시간          int64  \n",
      " 5   하차인원        float64\n",
      " 6   공휴일여부       int64  \n",
      " 7   강수량(mm)     float64\n",
      " 8   최저기온        float64\n",
      " 9   평균기온        float64\n",
      " 10  최고기온        float64\n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 287.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([adjust_df_2021,adjust_df_2022], ignore_index=True)\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_stations = len(np.unique(train_df['역번호']))\n",
    "num_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# 표준화할 컬럼 선택\\ncolumns_to_scale = ['미세먼지(pm10)', '평균기온', '최저기온', '최고기온', '강수량(mm)']\\n\\n# 표준화 진행\\nscaler = StandardScaler()\\ntrain_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale])\\n\\nimport pickle\\n# Scaler 저장\\nwith open('../models/scaler.pkl', 'wb') as f:\\n    pickle.dump(scaler, f)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 표준화할 컬럼 선택\n",
    "columns_to_scale = ['미세먼지(pm10)', '평균기온', '최저기온', '최고기온', '강수량(mm)']\n",
    "\n",
    "# 표준화 진행\n",
    "scaler = StandardScaler()\n",
    "train_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale])\n",
    "\n",
    "import pickle\n",
    "# Scaler 저장\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>역번호</th>\n",
       "      <th>요일</th>\n",
       "      <th>통과호선수</th>\n",
       "      <th>미세먼지(pm10)</th>\n",
       "      <th>시간</th>\n",
       "      <th>하차인원</th>\n",
       "      <th>공휴일여부</th>\n",
       "      <th>강수량(mm)</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>평균기온</th>\n",
       "      <th>최고기온</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>5.874931</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>4.983607</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.408427</td>\n",
       "      <td>6</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.408427</td>\n",
       "      <td>6</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.408427</td>\n",
       "      <td>6</td>\n",
       "      <td>4.700480</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.174910</td>\n",
       "      <td>6</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.26813</td>\n",
       "      <td>-1.739187</td>\n",
       "      <td>-1.653162</td>\n",
       "      <td>-1.568223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   역번호  요일  통과호선수  미세먼지(pm10)  시간      하차인원  공휴일여부  강수량(mm)      최저기온  \\\n",
       "0  150   4      4   -0.174910   6  5.874931      1 -0.26813 -1.739187   \n",
       "1  151   4      2   -0.174910   6  4.983607      1 -0.26813 -1.739187   \n",
       "2  152   4      1   -0.174910   6  4.762174      1 -0.26813 -1.739187   \n",
       "3  153   4      3   -0.174910   6  4.418841      1 -0.26813 -1.739187   \n",
       "4  154   4      1   -0.174910   6  4.127134      1 -0.26813 -1.739187   \n",
       "5  155   4      2   -0.174910   6  4.143135      1 -0.26813 -1.739187   \n",
       "6  156   4      3   -0.408427   6  4.219508      1 -0.26813 -1.739187   \n",
       "7  157   4      1   -0.408427   6  4.330733      1 -0.26813 -1.739187   \n",
       "8  158   4      1   -0.408427   6  4.700480      1 -0.26813 -1.739187   \n",
       "9  159   4      2   -0.174910   6  3.988984      1 -0.26813 -1.739187   \n",
       "\n",
       "       평균기온      최고기온  \n",
       "0 -1.653162 -1.568223  \n",
       "1 -1.653162 -1.568223  \n",
       "2 -1.653162 -1.568223  \n",
       "3 -1.653162 -1.568223  \n",
       "4 -1.653162 -1.568223  \n",
       "5 -1.653162 -1.568223  \n",
       "6 -1.653162 -1.568223  \n",
       "7 -1.653162 -1.568223  \n",
       "8 -1.653162 -1.568223  \n",
       "9 -1.653162 -1.568223  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MLP 모델\n",
    "2. RNN, LSTM, GRU\n",
    "3. Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (train_df.drop(['하차인원', '역번호'], axis=1)).values\n",
    "X_station = (train_df[['역번호']]).values\n",
    "y = (train_df['하차인원']).values\n",
    "\n",
    "X_train, X_val, X_station_train, X_station_val, y_train, y_val = train_test_split(X, X_station, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3082261, 9) (342474, 9) (3082261, 1) (342474, 1) (3082261,) (342474,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_station_train.shape, X_station_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 텐서로 변환\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_station_train_tensor = torch.LongTensor(X_station_train)  # 역번호는 범주형이므로 LongTensor로 변환\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "X_station_val_tensor = torch.LongTensor(X_station_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "\n",
    "# 데이터셋 및 데이터로더 구성\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, X_station_train_tensor, y_train_tensor)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, X_station_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithEmbedding(nn.Module):\n",
    "    def __init__(self, num_stations, embedding_dim, input_size):\n",
    "        super(MLPWithEmbedding, self).__init__()\n",
    "        # 역번호에 대한 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(num_stations, embedding_dim)\n",
    "        \n",
    "        # 임베딩 레이어와 다른 연속형 피처를 결합한 후 MLP를 구성\n",
    "        self.fc1 = nn.Linear(embedding_dim + input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x_numeric, x_station):\n",
    "        # 역번호 임베딩 처리\n",
    "        x_station_embedded = self.embedding(x_station)\n",
    "        x_station_embedded = x_station_embedded.squeeze(1)  # 임베딩 결과의 차원 조정\n",
    "        \n",
    "        # 임베딩된 역번호와 연속형 피처 결합\n",
    "        x = torch.cat([x_numeric, x_station_embedded], dim=1)\n",
    "        \n",
    "        # MLP 모델 진행\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     33\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs_numeric\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bus/lib/python3.11/site-packages/torch/optim/adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "embedding_dim = 8  # 임베딩 벡터의 차원\n",
    "input_size = X_train.shape[1]  # 연속형 피처 수\n",
    "model = MLPWithEmbedding(num_stations=num_stations, embedding_dim=embedding_dim, input_size=input_size)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.MSELoss()  # 회귀 문제이므로 MSE 사용\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 학습 및 검증\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "y_val_tensor = y_val_tensor.view(-1, 1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs_numeric, inputs_station, targets in train_loader:\n",
    "        inputs_numeric = inputs_numeric.to(device)\n",
    "        inputs_station = inputs_station.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)  # 타겟 텐서 크기 변환\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_numeric, inputs_station)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs_numeric.size(0)\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # TensorBoard에 학습 손실 기록\n",
    "    writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs_numeric, inputs_station, targets in val_loader:\n",
    "            inputs_numeric = inputs_numeric.to(device)\n",
    "            inputs_station = inputs_station.to(device)\n",
    "            targets = targets.to(device).view(-1, 1)  # 타겟 텐서 크기 변환\n",
    "            \n",
    "            outputs = model(inputs_numeric, inputs_station)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs_numeric.size(0)\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # TensorBoard에 검증 손실 기록\n",
    "    writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# 학습이 끝난 후 TensorBoard 기록 종료\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 결과 시각화\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
